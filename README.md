# üß† Python AI Assistant using OLLAMA Mistral

This is a simple Python-based AI Assistant that interacts with the **Mistral** language model using the [OLLAMA](https://ollama.com) local LLM runtime.

---

## ‚úÖ Features

- Command-line interface for chatting with Mistral.
- Local inference using OLLAMA (no API key needed).
- Lightweight and easy to set up.

---

## üì¶ Requirements

- Python 3.8 or higher
- OLLAMA installed locally with the Mistral model

---

## ‚öôÔ∏è Setup Instructions

### 1. Install OLLAMA

Download and install OLLAMA from: https://ollama.com/download  
Once installed, pull the Mistral model:

```bash
ollama run mistral
ollama serve 
